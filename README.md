# [Raghav Krishnakumar Sowmyanarayanan] - Data Scientist/ML Aspirant | Lead Data Engineer

Welcome to my GitHub repository! I am a passionate **Lead Data Engineer** aspiring to transition into the world of **Data Science**. With a strong foundation in **data engineering**, **data pipelines**, and **machine learning**, I am eager to leverage my experience in the engineering space to become a full-fledged **Data Scientist**.

Here, you'll find projects and work samples that demonstrate my progress, including:
- Data engineering pipelines
- Machine learning models
- Data wrangling and analysis projects
- Technical blog posts

---

## üöÄ About Me

I have over **9.3 years** of experience in **data engineering**, and I‚Äôm currently leading a team that builds scalable, robust data pipelines for enterprise-level systems. I am passionate about solving complex business problems using data and am transitioning to become a **Data Scientist** to deepen my expertise in **predictive modeling**, **machine learning**, and **data visualization**.

### Key Skills & Technologies
- **Programming Languages**: Python, SQL
- **Data Engineering**: Abinitio, Informatica Power Center, Apache Spark, Hadoop, Kafka, Airflow, ETL Pipelines
- **Data Science**: Machine Learning (Scikit-learn, TensorFlow, Keras), Model Deployment, Time Series Forecasting
- **Data Analysis**: Pandas, Numpy, Matplotlib, Seaborn
- **Big Data**: Spark, Hive, HBase
- **Cloud**: AWS (S3, EC2, Lambda, Redshift), Google Cloud Platform
- **Version Control**: Git, GitHub, GitLab
- **Databases**: MSSQL,DB2, NoSQL (MongoDB, Cassandra)
- **Data Visualization**: Tablea
- **Other Tools**: Docker, Kubernetes, Jupyter Notebooks, VS Code

---

## üìà Projects

Here are some of the projects I‚Äôve worked on, showcasing my skills in both **data engineering** and **data science**:

### 1. **[Project Name 1]** - Data Pipeline for Real-Time Analytics
- **Overview**: Built a real-time data pipeline using Apache Kafka and Apache Spark to ingest and process data in real-time for a financial application.
- **Tech Stack**: Kafka, Spark Streaming, Python, AWS Lambda, Redshift
- **Key Achievements**:
  - Developed a streaming ETL pipeline with minimal latency.
  - Optimized the pipeline for scalability and fault tolerance.
  
### 2. **[Project Name 2]** - Predictive Model for Customer Churn
- **Overview**: Developed a machine learning model to predict customer churn using logistic regression and decision trees.
- **Tech Stack**: Python, Scikit-learn, Pandas, Matplotlib, Seaborn
- **Key Achievements**:
  - Achieved 85% accuracy on test data.
  - Visualized model performance metrics and provided actionable business insights.

### 3. **[Project Name 3]** - Time Series Forecasting for Sales
- **Overview**: Built a time series model using ARIMA to forecast future sales for a retail company.
- **Tech Stack**: Python, Pandas, Numpy, Statsmodels
- **Key Achievements**:
  - Improved forecast accuracy by incorporating external factors (e.g., promotions, holidays).
  - Integrated the model into a dashboard for ongoing predictions.

### 4. **[Project Name 4]** - NLP Model for Text Classification
- **Overview**: Implemented a natural language processing model to classify customer feedback into various categories.
- **Tech Stack**: Python, Scikit-learn, NLTK, SpaCy, TensorFlow
- **Key Achievements**:
  - Achieved 92% accuracy using a combination of TF-IDF and neural network models.
  - Built an API for real-time classification using Flask.

---

## üíº Professional Experience

### Lead Data Engineer - [Infosys] (2024 - Present)
- **Responsibilities**:
  - Led the development and maintenance of data pipelines and workflows using Apache Spark, Kafka, and Airflow.
  - Optimized ETL processes for speed and reliability, reducing pipeline failures by X%.
  - Collaborated with data scientists to prepare and preprocess data for machine learning models.
  - Mentored junior engineers and helped scale the data infrastructure to handle larger datasets.


## üß† Learning Path & Goals

As I transition to Data Science, I‚Äôm actively working on deepening my knowledge in the following areas:

1. **Machine Learning**: Exploring advanced algorithms such as random forests, gradient boosting, and neural networks.
2. **Deep Learning**: Gaining hands-on experience with TensorFlow and PyTorch for image and text-based models.
3. **Data Science Tools**: Mastering advanced data visualization tools like Tableau and learning to deploy models into production environments using Docker, Kubernetes, and Flask.
4. **Statistical Methods**: Building a deeper understanding of statistical inference, hypothesis testing, and Bayesian methods.
5. **Project Management**: Applying agile methodologies in data science projects for improved team collaboration and project delivery.

---

## üìö Education & Certifications

- **Bachelor of Electrical and Electronics Engineering** - [Anna University]
- **Certified Data Scientist** - [Certifying Organization]
- **AWS Certified Solutions Architect** - [Certifying Organization]
- **Deep Learning Specialization** - Coursera (Andrew Ng)
- **Machine Learning with Python** - DataCamp

---

## üìù Blog & Publications

I write about my learning journey, data science concepts, and technical tutorials. Here are some of my latest blog posts:


---

## üì¨ Get in Touch

- **Email**: [mailmeraghav123@gmail.com]
- **LinkedIn**: [https://www.linkedin.com/in/raghav-krishnakumar-sowmyanarayanan-7a703a16b/]
- **GitHub**: [TBD]

---

## üèóÔ∏è How to Contribute

Feel free to explore the repositories in this portfolio. If you have any questions or would like to collaborate on a project, don't hesitate to open an issue or create a pull request.

---

### Final Thoughts:

Thank you for visiting my GitHub portfolio. As I continue to grow in the field of **Data Science**, I‚Äôm excited about the challenges ahead and the opportunity to apply my skills in a meaningful way. If you're interested in collaborating, feel free to reach out.

---
